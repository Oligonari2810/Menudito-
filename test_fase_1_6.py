#!/usr/bin/env python3
"""
ğŸ§ª TEST FASE 1.6 - VALIDACIÃ“N DE MEJORAS
Script para probar todas las funcionalidades de FASE 1.6
"""

import os
import sys
import logging
from datetime import datetime
from typing import Dict, List

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class Fase16Tester:
    """Tester para validar funcionalidades FASE 1.6"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.test_results = []
        
    def test_tp_sl_calculation(self) -> bool:
        """Test 1: Validar cÃ¡lculo de TP/SL dinÃ¡micos"""
        try:
            self.logger.info("ğŸ§ª Test 1: CÃ¡lculo de TP/SL dinÃ¡micos")
            
            # Simular SafetyManager con configuraciÃ³n FASE 1.6
            class MockSafetyManager:
                def __init__(self):
                    self.fee_taker_bps = 7.5
                    self.fee_maker_bps = 2.0
                    self.slippage_bps = 1.5
                    self.tp_buffer_bps = 2.0
                    self.tp_mode = "fixed_min"
                    self.tp_min_bps = 18.5
                    self.atr_period = 14
                    self.tp_atr_mult = 0.50
                    self.sl_atr_mult = 0.40
                
                def compute_trade_targets(self, price: float, atr_value: float = None) -> Dict[str, float]:
                    """Calcular TP y SL dinÃ¡micos con fricciÃ³n"""
                    fee_bps = max(self.fee_taker_bps, self.fee_maker_bps)
                    fric_bps = 2 * fee_bps + self.slippage_bps
                    tp_floor = fric_bps + self.tp_buffer_bps
                    
                    if self.tp_mode == "fixed_min":
                        tp_bps = max(self.tp_min_bps, tp_floor)
                        sl_bps = tp_bps / 1.25
                    else:
                        if atr_value is None:
                            atr_value = price * 0.01
                        atr_pct = (atr_value / price) * 100 * 100
                        tp_bps = max(self.tp_atr_mult * atr_pct, tp_floor)
                        sl_bps = max(self.sl_atr_mult * atr_pct, tp_floor / 1.25)
                    
                    return {
                        'tp_bps': tp_bps, 'sl_bps': sl_bps, 'tp_floor': tp_floor, 'fric_bps': fric_bps,
                        'rr_ratio': tp_bps / sl_bps if sl_bps > 0 else 0,
                        'tp_pct': tp_bps / 10000, 'sl_pct': sl_bps / 10000
                    }
            
            # Ejecutar tests
            safety = MockSafetyManager()
            
            # Test 1.1: TP mÃ­nimo nunca menor a fricciÃ³n
            price = 600.0
            targets = safety.compute_trade_targets(price)
            
            assert targets['tp_bps'] >= targets['tp_floor'], f"TP {targets['tp_bps']} < floor {targets['tp_floor']}"
            self.logger.info(f"âœ… TP mÃ­nimo: {targets['tp_bps']:.1f} bps >= floor {targets['tp_floor']:.1f} bps")
            
            # Test 1.2: RR â‰¥ 1.25
            assert targets['rr_ratio'] >= 1.25, f"RR {targets['rr_ratio']:.2f} < 1.25"
            self.logger.info(f"âœ… RR: {targets['rr_ratio']:.2f}:1 >= 1.25:1")
            
            # Test 1.3: FricciÃ³n calculada correctamente
            expected_fric = 2 * max(7.5, 2.0) + 1.5  # 16.5 bps
            assert abs(targets['fric_bps'] - expected_fric) < 0.1, f"FricciÃ³n {targets['fric_bps']} != {expected_fric}"
            self.logger.info(f"âœ… FricciÃ³n: {targets['fric_bps']:.1f} bps")
            
            self.test_results.append(("TP/SL Calculation", True, "âœ… Passed"))
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Test 1 failed: {e}")
            self.test_results.append(("TP/SL Calculation", False, f"âŒ Failed: {e}"))
            return False
    
    def test_market_filters(self) -> bool:
        """Test 2: Validar filtros de mercado"""
        try:
            self.logger.info("ğŸ§ª Test 2: Filtros de mercado")
            
            class MockSafetyManager:
                def __init__(self):
                    self.min_range_bps = 5.0
                    self.max_spread_bps = 2.0
                    self.min_vol_usd = 5000000
                    self.max_ws_latency_ms = 1500
                    self.max_rest_latency_ms = 800
                
                def pre_trade_filters(self, market_data: Dict) -> Dict[str, any]:
                    """Aplicar filtros previos al trade"""
                    filter_result = {
                        'passed': True,
                        'reason': 'OK',
                        'details': {},
                        'warnings': []
                    }
                    
                    current_price = market_data.get('price', 0.0)
                    high = market_data.get('high', current_price)
                    low = market_data.get('low', current_price)
                    close = market_data.get('close', current_price)
                    best_ask = market_data.get('best_ask', current_price)
                    best_bid = market_data.get('best_bid', current_price)
                    volume_usd = market_data.get('volume_usd', 0.0)
                    ws_latency_ms = market_data.get('ws_latency_ms', 0.0)
                    rest_latency_ms = market_data.get('rest_latency_ms', 0.0)
                    
                    # 1. Filtro de rango
                    if close > 0:
                        range_pct = ((high - low) / close) * 100
                        range_bps = range_pct * 100
                        
                        if range_bps < self.min_range_bps:
                            filter_result['passed'] = False
                            filter_result['reason'] = 'LOW_RANGE'
                            return filter_result
                    
                    # 2. Filtro de spread
                    if best_ask > 0 and best_bid > 0:
                        mid_price = (best_ask + best_bid) / 2
                        spread_pct = ((best_ask - best_bid) / mid_price) * 100
                        spread_bps = spread_pct * 100
                        
                        if spread_bps > self.max_spread_bps:
                            filter_result['passed'] = False
                            filter_result['reason'] = 'HIGH_SPREAD'
                            return filter_result
                    
                    # 3. Filtro de volumen
                    if volume_usd < self.min_vol_usd:
                        filter_result['passed'] = False
                        filter_result['reason'] = 'LOW_VOLUME'
                        return filter_result
                    
                    # 4. Filtro de latencia
                    if ws_latency_ms > self.max_ws_latency_ms:
                        filter_result['passed'] = False
                        filter_result['reason'] = 'HIGH_WS_LAT'
                        return filter_result
                    
                    if rest_latency_ms > self.max_rest_latency_ms:
                        filter_result['passed'] = False
                        filter_result['reason'] = 'HIGH_REST_LAT'
                        return filter_result
                    
                    return filter_result
            
            safety = MockSafetyManager()
            
            # Test 2.1: Filtro de rango vÃ¡lido con spread bajo
            market_data = {
                'price': 600.0,
                'high': 600.5,
                'low': 599.5,
                'close': 600.0,
                'best_ask': 600.001,  # Spread muy bajo
                'best_bid': 599.999,  # Spread muy bajo
                'volume_usd': 10000000,
                'ws_latency_ms': 100,
                'rest_latency_ms': 200
            }
            
            result = safety.pre_trade_filters(market_data)
            range_bps = ((600.5 - 599.5) / 600.0) * 100 * 100  # 16.67 bps
            self.logger.info(f"Rango calculado: {range_bps:.1f} bps")
            self.logger.info(f"Resultado filtro: {result}")
            assert result['passed'], "DeberÃ­a aceptar rango vÃ¡lido con spread bajo"
            self.logger.info(f"âœ… Filtro rango: Aceptado {range_bps:.1f} bps >= 5.0 bps")
            
            # Test 2.2: Filtro de spread alto
            market_data['best_ask'] = 600.5
            market_data['best_bid'] = 599.5
            result = safety.pre_trade_filters(market_data)
            spread_bps = ((600.5 - 599.5) / 600.0) * 100 * 100  # 16.67 bps
            assert not result['passed'], "DeberÃ­a rechazar spread alto"
            self.logger.info(f"âœ… Filtro spread: Rechazado {spread_bps:.1f} bps > 2.0 bps")
            
            self.test_results.append(("Market Filters", True, "âœ… Passed"))
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Test 2 failed: {e}")
            self.test_results.append(("Market Filters", False, f"âŒ Failed: {e}"))
            return False
    
    def test_pnl_realistic(self) -> bool:
        """Test 3: Validar cÃ¡lculo de P&L realista"""
        try:
            self.logger.info("ğŸ§ª Test 3: P&L realista con fees/slippage")
            
            class MockSafetyManager:
                def __init__(self):
                    self.fee_taker_bps = 7.5
                    self.fee_maker_bps = 2.0
                    self.slippage_bps = 1.5
                
                def calculate_fees_and_slippage(self, trade_data: Dict) -> Dict[str, float]:
                    notional = trade_data.get('notional', 0.0)
                    intended_price = trade_data.get('intended_price', 0.0)
                    executed_price = trade_data.get('executed_price', 0.0)
                    
                    fee_rate = self.fee_taker_bps / 10000
                    entry_fee = notional * fee_rate
                    exit_fee = notional * fee_rate
                    total_fees = entry_fee + exit_fee
                    
                    if intended_price > 0 and executed_price > 0:
                        slippage_pct = abs(executed_price - intended_price) / intended_price
                        slippage_cost = notional * slippage_pct
                    else:
                        slippage_pct = 0.0
                        slippage_cost = 0.0
                    
                    fees_bps = (total_fees / notional) * 10000 if notional > 0 else 0
                    slippage_bps = slippage_pct * 10000
                    
                    return {
                        'entry_fee': entry_fee,
                        'exit_fee': exit_fee,
                        'total_fees': total_fees,
                        'fees_bps': fees_bps,
                        'slippage_cost': slippage_cost,
                        'slippage_bps': slippage_bps,
                        'slippage_pct': slippage_pct,
                        'total_friction': total_fees + slippage_cost
                    }
                
                def calculate_net_pnl(self, trade_data: Dict) -> Dict[str, float]:
                    gross_pnl = trade_data.get('realized_pnl', 0.0)
                    friction_data = self.calculate_fees_and_slippage(trade_data)
                    net_pnl = gross_pnl - friction_data['total_friction']
                    
                    return {
                        'gross_pnl': gross_pnl,
                        'net_pnl': net_pnl,
                        'fees_cost': friction_data['total_fees'],
                        'slippage_cost': friction_data['slippage_cost'],
                        'total_friction': friction_data['total_friction'],
                        'friction_impact': (friction_data['total_friction'] / abs(gross_pnl) * 100) if gross_pnl != 0 else 0
                    }
            
            safety = MockSafetyManager()
            
            # Test 3.1: P&L neto < P&L bruto
            trade_data = {
                'notional': 100.0,
                'intended_price': 600.0,
                'executed_price': 600.3,  # 0.05% slippage
                'realized_pnl': 5.0  # $5 ganancia bruta
            }
            
            pnl_data = safety.calculate_net_pnl(trade_data)
            
            assert pnl_data['net_pnl'] < pnl_data['gross_pnl'], "P&L neto debe ser menor al bruto"
            self.logger.info(f"âœ… P&L: Bruto=${pnl_data['gross_pnl']:.4f} > Neto=${pnl_data['net_pnl']:.4f}")
            
            # Test 3.2: Fees calculadas correctamente
            expected_fees = 100.0 * (7.5 / 10000) * 2  # entrada + salida
            assert abs(pnl_data['fees_cost'] - expected_fees) < 0.01, f"Fees {pnl_data['fees_cost']} != {expected_fees}"
            self.logger.info(f"âœ… Fees: ${pnl_data['fees_cost']:.4f}")
            
            # Test 3.3: Slippage calculado correctamente
            expected_slippage = 100.0 * 0.0005  # 0.05%
            assert abs(pnl_data['slippage_cost'] - expected_slippage) < 0.01, f"Slippage {pnl_data['slippage_cost']} != {expected_slippage}"
            self.logger.info(f"âœ… Slippage: ${pnl_data['slippage_cost']:.4f}")
            
            self.test_results.append(("Realistic P&L", True, "âœ… Passed"))
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Test 3 failed: {e}")
            self.test_results.append(("Realistic P&L", False, f"âŒ Failed: {e}"))
            return False
    
    def test_latency_validation(self) -> bool:
        """Test 4: Validar validaciÃ³n de latencia"""
        try:
            self.logger.info("ğŸ§ª Test 4: ValidaciÃ³n de latencia")
            
            # Simular validaciÃ³n de latencia
            max_rest_latency_ms = 800
            max_ws_latency_ms = 1500
            
            # Test 4.1: Latencia REST vÃ¡lida
            rest_latency = 500
            ws_latency = 800
            
            rest_ok = rest_latency <= max_rest_latency_ms
            ws_ok = ws_latency <= max_ws_latency_ms
            
            assert rest_ok, f"REST latency {rest_latency}ms > {max_rest_latency_ms}ms"
            assert ws_ok, f"WS latency {ws_latency}ms > {max_ws_latency_ms}ms"
            
            self.logger.info(f"âœ… Latencia REST: {rest_latency}ms <= {max_rest_latency_ms}ms")
            self.logger.info(f"âœ… Latencia WS: {ws_latency}ms <= {max_ws_latency_ms}ms")
            
            # Test 4.2: Latencia alta (deberÃ­a fallar)
            high_rest_latency = 1000
            high_ws_latency = 2000
            
            rest_high_ok = high_rest_latency <= max_rest_latency_ms
            ws_high_ok = high_ws_latency <= max_ws_latency_ms
            
            assert not rest_high_ok, f"REST latency alta {high_rest_latency}ms deberÃ­a fallar"
            assert not ws_high_ok, f"WS latency alta {high_ws_latency}ms deberÃ­a fallar"
            
            self.logger.info(f"âœ… ValidaciÃ³n latencia alta: REST {high_rest_latency}ms > {max_rest_latency_ms}ms")
            self.logger.info(f"âœ… ValidaciÃ³n latencia alta: WS {high_ws_latency}ms > {max_ws_latency_ms}ms")
            
            self.test_results.append(("Latency Validation", True, "âœ… Passed"))
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Test 4 failed: {e}")
            self.test_results.append(("Latency Validation", False, f"âŒ Failed: {e}"))
            return False
    
    def test_order_validation(self) -> bool:
        """Test 5: Validar validaciÃ³n de Ã³rdenes"""
        try:
            self.logger.info("ğŸ§ª Test 5: ValidaciÃ³n de Ã³rdenes")
            
            # Simular validaciÃ³n de parÃ¡metros de orden
            def validate_order_parameters(notional: float, min_notional: float = 5.0) -> bool:
                return notional >= min_notional
            
            # Test 5.1: Notional vÃ¡lido
            valid_notional = 10.0
            assert validate_order_parameters(valid_notional), f"Notional {valid_notional} deberÃ­a ser vÃ¡lido"
            self.logger.info(f"âœ… Notional vÃ¡lido: ${valid_notional} >= $5.0")
            
            # Test 5.2: Notional invÃ¡lido
            invalid_notional = 3.0
            assert not validate_order_parameters(invalid_notional), f"Notional {invalid_notional} deberÃ­a ser invÃ¡lido"
            self.logger.info(f"âœ… Notional invÃ¡lido: ${invalid_notional} < $5.0")
            
            # Test 5.3: PrecisiÃ³n de precio
            def validate_price_precision(price: float, tick_size: float = 0.001) -> bool:
                return abs(price % tick_size) < 0.0001
            
            valid_price = 600.123
            invalid_price = 600.1234
            
            assert validate_price_precision(valid_price), f"Precio {valid_price} deberÃ­a ser vÃ¡lido"
            assert not validate_price_precision(invalid_price), f"Precio {invalid_price} deberÃ­a ser invÃ¡lido"
            
            self.logger.info(f"âœ… PrecisiÃ³n de precio: {valid_price} vÃ¡lido, {invalid_price} invÃ¡lido")
            
            self.test_results.append(("Order Validation", True, "âœ… Passed"))
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Test 5 failed: {e}")
            self.test_results.append(("Order Validation", False, f"âŒ Failed: {e}"))
            return False
    
    def run_all_tests(self) -> Dict[str, any]:
        """Ejecutar todos los tests"""
        self.logger.info("ğŸš€ Iniciando tests FASE 1.6...")
        
        tests = [
            self.test_tp_sl_calculation,
            self.test_market_filters,
            self.test_pnl_realistic,
            self.test_latency_validation,
            self.test_order_validation
        ]
        
        passed = 0
        total = len(tests)
        
        for test in tests:
            if test():
                passed += 1
        
        # Resumen
        self.logger.info("\n" + "="*50)
        self.logger.info("ğŸ“Š RESUMEN DE TESTS FASE 1.6")
        self.logger.info("="*50)
        
        for test_name, success, message in self.test_results:
            status = "âœ… PASS" if success else "âŒ FAIL"
            self.logger.info(f"{status} - {test_name}: {message}")
        
        self.logger.info("="*50)
        self.logger.info(f"ğŸ“ˆ Resultado: {passed}/{total} tests pasaron")
        
        if passed == total:
            self.logger.info("ğŸ‰ Â¡TODOS LOS TESTS FASE 1.6 PASARON!")
        else:
            self.logger.error(f"âŒ {total - passed} tests fallaron")
        
        return {
            'passed': passed,
            'total': total,
            'success_rate': passed / total * 100,
            'results': self.test_results
        }

def main():
    """FunciÃ³n principal"""
    try:
        tester = Fase16Tester()
        results = tester.run_all_tests()
        
        if results['passed'] == results['total']:
            print("\nğŸ‰ Â¡FASE 1.6 VALIDADA EXITOSAMENTE!")
            print("âœ… Todas las mejoras estÃ¡n funcionando correctamente")
            print("ğŸš€ El bot estÃ¡ listo para producciÃ³n con FASE 1.6")
            return 0
        else:
            print(f"\nâŒ FASE 1.6: {results['total'] - results['passed']} tests fallaron")
            print("ğŸ”§ Revisar implementaciÃ³n antes de desplegar")
            return 1
            
    except Exception as e:
        logging.error(f"âŒ Error crÃ­tico en tests FASE 1.6: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
